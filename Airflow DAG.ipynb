{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f470ef1d",
   "metadata": {},
   "source": [
    "### Apache Airflow is an open-source workflow management platform that allows you to programmatically author, schedule, and monitor workflows. It is highly scalable and extensible, making it a good choice for automating complex data pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357ef3f0",
   "metadata": {},
   "source": [
    "# Converting the whole pipeline into resuable functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bc51df6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data(ticker:str):\n",
    "    import yfinance as yf\n",
    "    df=yf.download(ticker,period='max',auto_adjust=False)\n",
    "    df=df.reset_index()\n",
    "    df.columns=['Date','Adj Close','Close','High','Low','Open','Volume']\n",
    "    beginning_cols=['Date','Open','Close','Adj Close']\n",
    "    later_cols=[c for c in df.columns if c not in beginning_cols]\n",
    "    df=df[beginning_cols+later_cols]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7737abb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def feature_engineering(df:pd.DataFrame):\n",
    "    from ta.trend import MACD\n",
    "    from ta.momentum import RSIIndicator\n",
    "    # 1. MACD\n",
    "    # adds MACD Line,Signal Line and MACD histogram\n",
    "    macd_indicator=MACD(close=df['Adj Close'],window_fast=12,window_slow=26,window_sign=9,fillna=False)\n",
    "\n",
    "    df['MACD_Line']=macd_indicator.macd()\n",
    "    df['MACD_Signal']=macd_indicator.macd_signal()\n",
    "    df['MACD_Histogram']=macd_indicator.macd_diff()\n",
    "\n",
    "    # 2. RSI\n",
    "    rsi_indicator=RSIIndicator(close=df['Adj Close'],window=14,fillna=False)\n",
    "    df['RSI_14']=rsi_indicator.rsi()\n",
    "\n",
    "    # 3. Daily % Return\n",
    "    df['Daily % Return']=100*(df['Close']-df['Close'].shift(1))/df['Close'].shift(1)\n",
    "\n",
    "    # 4. MA (Moving Averages)\n",
    "    ma_windows=[10,20,50,100,200]\n",
    "    for w in ma_windows:\n",
    "        df[f'SMA_{w}']=df['Adj Close'].rolling(window=w).mean()           # SMA features\n",
    "        df[f'EMA_{w}']=df['Adj Close'].ewm(span=w,adjust=False).mean()    # EMA features\n",
    "\n",
    "    df=df.fillna(0)\n",
    "\n",
    "    # 5. Close Lags\n",
    "    def create_lags(data,column='Close',lags=[2,5,7,14]):\n",
    "        for lag in lags:\n",
    "            data[f'{column}_LAG{lag}']=data[column].shift(lag)\n",
    "        return data\n",
    "\n",
    "    lags=[1,2,3,5,7,14]\n",
    "    df=create_lags(df,column='Close',lags=lags)\n",
    "    df=df.dropna()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e2d26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(df,n_steps=100,k=1):\n",
    "    train_size=int(len(df)*0.8)\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    scaler=MinMaxScaler(feature_range=(0,1))\n",
    "    data=scaler.fit_transform(df[['Adj Close']])\n",
    "    import numpy as np\n",
    "    x=[]\n",
    "    y=[]\n",
    "    for i in range(n_steps,len(df)-k+1):\n",
    "        x.append(data[i-n_steps:i])    # past n days\n",
    "        y.append(data[i:i+k])          # next k days\n",
    "    x=np.array(x)\n",
    "    y=np.array(y)\n",
    "    x=x.reshape((x.shape[0],x.shape[1],1))\n",
    "    y_train,y_test=y[:train_size],y[train_size-n_steps:]\n",
    "    x_train,x_test=x[:train_size],x[train_size-n_steps:]\n",
    "    \n",
    "    import tensorflow\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import GRU,Dense\n",
    "    model=Sequential([\n",
    "        GRU(80,input_shape=(x_train.shape[1],1),return_sequences=True),\n",
    "        GRU(60),\n",
    "        Dense(y_train.shape[1])\n",
    "    ])\n",
    "    model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "    history=model.fit(x_train,y_train,epochs=30,batch_size=32,validation_split=0.2,verbose=-1)\n",
    "    model.save('models/finsight_gru.h5')\n",
    "    print(\"âœ… Model trained and saved.\")\n",
    "    return model,scaler,x_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "6b8bd89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model,scaler,x_test):\n",
    "    y_pred=model.predict(x_test)\n",
    "    y_final=scaler.inverse_transform(y_pred)\n",
    "    return y_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be84312",
   "metadata": {},
   "source": [
    "# Creating the Airflow DAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68f11d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
